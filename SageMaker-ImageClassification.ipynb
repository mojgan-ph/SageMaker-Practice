{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "import boto3\n",
    "bucket_name='my_bucket_name'\n",
    "data_set='jpeg/train'\n",
    "region = boto3.Session().region_name\n",
    "# s3train_path = 'https://s3-{}.amazonaws.com/{}/{}'.format(region,bucket_name, data_set)\n",
    "s3train_path='s3://{}/jpeg/train/'.format(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "role= get_execution_role()\n",
    "sess=sagemaker.Session()\n",
    "training_image=get_image_uri(sess.boto_region_name, 'image-classification', repo_version='latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location='s3://{}/{}/output'.format(bucket_name, 'jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommended input format for the Amazon SageMaker image classification algorithms is Apache MXNet RecordIO. With that format, the training process uses the data in pipe mode rather than file mode. Pipe mode is faster because it makes an stream of data instead of copying batches of data one by one. In pipe mode the training job does not have to wait for the data to arrive before starting the process on each bach. However, we can also have jpeg or png files and make it be used in pipe by using an augmented manifest file. Find more information here: https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make augmented manifest file for train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='path_to_train.csv'\n",
    "df=pd.read_csv(path)\n",
    "df.loc[:, 'file_name']= df.loc[:,'image_name']+'.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make train and validation sets\n",
    "from sklearn.utils import shuffle\n",
    "df=shuffle(df)\n",
    "val_size=int(df.shape[0]/10)\n",
    "df_val=df[0:val_size]\n",
    "df=df[val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate mallignant cases for 55 times to make the data balanced!\n",
    "df_mallignant=df[df['target']==1]\n",
    "for i in range(55):\n",
    "    df=df.append(df_mallignant)\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make augmented manifest file for train dataset\n",
    "df_manifest= df[['file_name', 'target']]\n",
    "df_manifest['file_name']= 's3://{}/jpeg/train/'.format(bucket_name)+df_manifest['file_name']\n",
    "df_manifest.columns=['source-ref', 'class']\n",
    "out=json.dumps(json.loads(df_manifest.to_json(orient='records')))[1:-1].replace('}, {', \"}\\n{\")\n",
    "with open('../data/train_manifest', 'w') as f:\n",
    "    f.write(out)\n",
    "s3_client = boto3.client('s3')\n",
    "s3_client.upload_file('../data/train_manifest', Bucket=bucket_name, Key='jpeg/train_manifest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make augmented manifest file for validation dataset\n",
    "df_val_manifest= df_val[['file_name', 'target']]\n",
    "df_val_manifest['file_name']= 's3://{}/jpeg/train/'.format(bucket_name)+df_val_manifest['file_name']\n",
    "df_val_manifest.columns=['source-ref', 'class']\n",
    "out=json.dumps(json.loads(df_val_manifest.to_json(orient='records')))[1:-1].replace('}, {', \"}\\n{\")\n",
    "with open('../data/validation_manifest', 'w') as f:\n",
    "    f.write(out)\n",
    "s3_client = boto3.client('s3')\n",
    "s3_client.upload_file('../data/validation_manifest', Bucket=bucket_name, Key='jpeg/validation_manifest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train in pipe mode with augmented manifest files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model object set to using \"Pipe\" mode.\n",
    "model = sagemaker.estimator.Estimator(training_image,\n",
    "                                      role,\n",
    "                                      train_instance_count=1,\n",
    "                                      train_instance_type='ml.p3.2xlarge', \n",
    "                                      train_volume_size = 20, \n",
    "                                      train_max_run = 3600*5,\n",
    "                                      input_mode = 'Pipe',\n",
    "                                      output_path=s3_output_location,\n",
    "                                      sagemaker_session=sess)\n",
    "#                                     model_uri= 's3-address-of-an-existing-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_hyperparameters=dict(\n",
    "    use_pretrained_model=1,\n",
    "    image_shape='3,224,224',\n",
    "    num_classes=2,\n",
    "    num_training_samples=58084,\n",
    ")\n",
    "\n",
    "hyperparameters={\n",
    "    **base_hyperparameters,\n",
    "    **dict(\n",
    "        learning_rate=0.001,\n",
    "        mini_batch_size=32, \n",
    "        num_layers= 101,\n",
    "        epochs=4,\n",
    "        top_k=2\n",
    "    )\n",
    "}\n",
    "\n",
    "model.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train data channel with S3_data_type as 'AugmentedManifestFile' and attribute names.\n",
    "train_data = sagemaker.session.s3_input('s3://{}/jpeg/train_manifest'.format(bucket_name),\n",
    "    distribution='FullyReplicated',\n",
    "    content_type='application/x-recordio',\n",
    "    s3_data_type='AugmentedManifestFile', # if recordIO files were use, it should have been set to's3Prefix'\n",
    "    attribute_names=['source-ref', 'class'],\n",
    "    input_mode='Pipe',\n",
    "    record_wrapping='RecordIO') \n",
    "\n",
    "validation_data=sagemaker.session.s3_input('s3://{}/jpeg/validation_manifest'.format(bucket_name),\n",
    "    distribution='FullyReplicated',\n",
    "    content_type='application/x-recordio',\n",
    "    s3_data_type='AugmentedManifestFile', \n",
    "    attribute_names=['source-ref', 'class'],\n",
    "    input_mode='Pipe',\n",
    "    record_wrapping='RecordIO') \n",
    "\n",
    "data_channels = {'train': train_data, 'validation':validation_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(inputs=data_channels, job_name='my_training_job_name', logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job=model.latest_training_job\n",
    "job_name=job.name\n",
    "print(f\"available for download at: {model.output_path}/{job_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_addr='s3://{}/jpeg/output/my_training_job_name/output/model.tar.gz'.format(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sagemaker.model.Model(\n",
    "    model_data=model_addr, \n",
    "    image=training_image,\n",
    "    role=role, \n",
    "    sagemaker_session=sess \n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The location of the test dataset\n",
    "batch_input = 's3://{}/jpeg/test'.format(bucket_name)\n",
    "\n",
    "# The location to store the results of the batch transform job\n",
    "batch_output = '{}/inference_output'.format(s3_output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#I tried doing batch inference in pipe mode (by provding manifest files), but it does not work. \n",
    "#Does not raise an error, and does not produce the output files\n",
    "#so, here I am doing it in file mode\n",
    "transformer = model.transformer(instance_count=1, instance_type='ml.m4.xlarge', output_path=batch_output)\n",
    "transformer.transform(data=batch_input, data_type='S3Prefix', content_type='image/jpeg', split_type=None)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is how I tied doing the batch inference in pipe mode\n",
    "test_manifest='s3://{}/jpeg/test_manifest'.format(bucket_name)\n",
    "transformer= model.transformer(instance_count=1, instance_type='ml.m4.4xlarge', assemble_with='Line',\n",
    "                               output_path=s3_output_location)transformer.transform(data= test_manifest , \n",
    "    data_type='ManifestFile', \n",
    "    job_name='melanoma-first-transform-job-7',#if I do not give a name, it will do so automatically with date and time\n",
    "    content_type='application/x-recordio',\n",
    "    split_type='Line')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I downloaded the whole folder that contains the output of batch transform to my own computer. Then I made the submission file as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os;\n",
    "import json\n",
    "\n",
    "output = \"image_name,target\\n\"\n",
    "for file in os.listdir(path/'output_folder'):\n",
    "    jpg_name = os.path.splitext(os.path.splitext(file)[0])[0]\n",
    "    with open(str(path/'output_folder')+\"/\"+file) as f:\n",
    "        data = json.load(f)\n",
    "        value = round(data['prediction'][1], 4)\n",
    "        output = output + jpg_name + \",\"+str(value) + \"\\n\"\n",
    "\n",
    "with open(path/'my_submission.csv', 'w') as sub:\n",
    "    sub.write(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
